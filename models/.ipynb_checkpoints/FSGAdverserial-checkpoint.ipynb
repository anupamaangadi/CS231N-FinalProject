{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#VGG 19 Model and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import urllib\n",
    "import io\n",
    "import skimage.transform\n",
    "from gen_adver import FastGradient\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano import pp\n",
    "\n",
    "import lasagne\n",
    "from lasagne.layers import InputLayer, DenseLayer, DropoutLayer\n",
    "from lasagne.layers.conv import Conv2DLayer as ConvLayer\n",
    "from lasagne.layers.pool import Pool2DLayer as PoolLayer\n",
    "from lasagne.layers import NonlinearityLayer\n",
    "from lasagne.layers import DropoutLayer\n",
    "from lasagne.layers import LocalResponseNormalization2DLayer as NormLayer\n",
    "from lasagne.utils import floatX\n",
    "from lasagne.nonlinearities import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_image(url,mean_image):\n",
    "    ext = url.split('.')[-1]\n",
    "    im = plt.imread(io.BytesIO(urllib.urlopen(url).read()), ext)\n",
    "    # Resize so smallest dim = 256, preserving aspect ratio\n",
    "    h, w, _ = im.shape\n",
    "    if h < w:\n",
    "        im = skimage.transform.resize(im, (256, w*256/h), preserve_range=True)\n",
    "    else:\n",
    "        im = skimage.transform.resize(im, (h*256/w, 256), preserve_range=True)\n",
    "\n",
    "    # Central crop to 224x224\n",
    "    h, w, _ = im.shape\n",
    "    im = im[h//2-112:h//2+112, w//2-112:w//2+112]\n",
    "    rawim = np.copy(im).astype('uint8')\n",
    "    \n",
    "    # Shuffle axes to c01\n",
    "    im = np.swapaxes(np.swapaxes(im, 1, 2), 0, 1)\n",
    "    \n",
    "    # Convert to BGR\n",
    "    im = im[::-1, :, :]\n",
    "    im = im - mean_image[:,None,None]\n",
    "    return rawim, floatX(im[np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model to be trained/tested against\n",
    "\n",
    "def build_model(input_var,batch_size = None):\n",
    "    net = {}\n",
    "    net['input'] = InputLayer((batch_size, 3, 224, 224),input_var=input_var)\n",
    "    net['conv1_1'] = ConvLayer(\n",
    "        net['input'], 64, 3, pad=1)\n",
    "    net['conv1_2'] = ConvLayer(\n",
    "        net['conv1_1'], 64, 3, pad=1)\n",
    "    net['pool1'] = PoolLayer(net['conv1_2'], 2)\n",
    "    net['conv2_1'] = ConvLayer(\n",
    "        net['pool1'], 128, 3, pad=1)\n",
    "    net['conv2_2'] = ConvLayer(\n",
    "        net['conv2_1'], 128, 3, pad=1)\n",
    "    net['pool2'] = PoolLayer(net['conv2_2'], 2)\n",
    "    net['conv3_1'] = ConvLayer(\n",
    "        net['pool2'], 256, 3, pad=1)\n",
    "    net['conv3_2'] = ConvLayer(\n",
    "        net['conv3_1'], 256, 3, pad=1)\n",
    "    net['conv3_3'] = ConvLayer(\n",
    "        net['conv3_2'], 256, 3, pad=1)\n",
    "    net['conv3_4'] = ConvLayer(\n",
    "        net['conv3_3'], 256, 3, pad=1)\n",
    "    net['pool3'] = PoolLayer(net['conv3_4'], 2)\n",
    "    net['conv4_1'] = ConvLayer(\n",
    "        net['pool3'], 512, 3, pad=1)\n",
    "    net['conv4_2'] = ConvLayer(\n",
    "        net['conv4_1'], 512, 3, pad=1)\n",
    "    net['conv4_3'] = ConvLayer(\n",
    "        net['conv4_2'], 512, 3, pad=1)\n",
    "    net['conv4_4'] = ConvLayer(\n",
    "        net['conv4_3'], 512, 3, pad=1)\n",
    "    net['pool4'] = PoolLayer(net['conv4_4'], 2)\n",
    "    net['conv5_1'] = ConvLayer(\n",
    "        net['pool4'], 512, 3, pad=1)\n",
    "    net['conv5_2'] = ConvLayer(\n",
    "        net['conv5_1'], 512, 3, pad=1)\n",
    "    net['conv5_3'] = ConvLayer(\n",
    "        net['conv5_2'], 512, 3, pad=1)\n",
    "    net['conv5_4'] = ConvLayer(\n",
    "        net['conv5_3'], 512, 3, pad=1)\n",
    "    net['pool5'] = PoolLayer(net['conv5_4'], 2)\n",
    "    net['fc6'] = DenseLayer(net['pool5'], num_units=4096)\n",
    "    net['fc6_dropout'] = DropoutLayer(net['fc6'], p=0.5)\n",
    "    net['fc7'] = DenseLayer(net['fc6_dropout'], num_units=4096)\n",
    "    net['fc7_dropout'] = DropoutLayer(net['fc7'], p=0.5)\n",
    "    net['fc8'] = DenseLayer(\n",
    "        net['fc7_dropout'], num_units=1000, nonlinearity=None)\n",
    "    net['prob'] = NonlinearityLayer(net['fc8'], softmax)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load model parameters and metadata\n",
    "def load_data():\n",
    "    model = pickle.load(open('/afs/ir/users/m/e/meric/Documents/CS231N/CS231N-FinalProject/datasets/vgg19.pkl'))\n",
    "\n",
    "    classes = model['synset words']\n",
    "    mean_image= model['mean value']\n",
    "    \n",
    "    return model, classes, mean_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_val_images (num_ex, mean_image,gold_labels):\n",
    "    ''' \n",
    "    Dynamically downloads sample images from ImageNet.  \n",
    "    '''\n",
    "    index = urllib.urlopen('http://www.image-net.org/challenges/LSVRC/2012/ori_urls/indexval.html').read()\n",
    "    image_urls = index.split('<br>')\n",
    "    final_labels = gold_labels.copy()\n",
    "    np.random.seed(37)\n",
    "    np.random.shuffle(image_urls)\n",
    "    np.random.seed(37)\n",
    "    np.random.shuffle(final_labels)\n",
    "    result_labels = np.zeros(num_ex)\n",
    "\n",
    "    images = np.zeros ((num_ex, 3, 224, 224), dtype=np.float32)\n",
    "    i = 0\n",
    "    j = 0\n",
    "    used=True\n",
    "    rawim = np.zeros ((num_ex, 224, 224, 3), dtype=np.float32)\n",
    "    for im_url in image_urls:\n",
    "        print i, im_url\n",
    "        # only use quick downloads on flickr\n",
    "        if 'static.flickr' not in im_url:\n",
    "            continue\n",
    "            \n",
    "        rawim[i,:,:,:], result = prep_image (im_url, mean_image)\n",
    "      \n",
    "        if result.any():\n",
    "            images[i,:,:,:] = result\n",
    "            result_labels[i] = final_labels[j]\n",
    "            i += 1\n",
    "           \n",
    "        if i >= num_ex: \n",
    "            break\n",
    "        j += 1\n",
    "            \n",
    "    print images.shape\n",
    "    return rawim,images,result_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_gold_labels():\n",
    "    f = open(\"../datasets/val_gold_labels.txt\",'r')\n",
    "    labels = []\n",
    "    for line in f:\n",
    "        labels.append(int(line))\n",
    "        \n",
    "    return np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def find_adverserial_examples(tot_images=1,batch_size=1):\n",
    "    \n",
    "    cls = FastGradient(num_images = batch_size,input_dim=(3,224,224), eps=0.7, \n",
    "                   loss='softmax')\n",
    "    model, classes, mean_image = load_data()\n",
    "    gold_labels = load_gold_labels()\n",
    "    rawim, images,gold_labels = download_val_images (tot_images, mean_image, gold_labels)\n",
    "    input_var = T.tensor4('inputs')\n",
    "    net = build_model(input_var,batch_size=batch_size)\n",
    "    lasagne.layers.set_all_param_values(net['prob'], model['param values'])\n",
    "\n",
    "    if batch_size > tot_images:\n",
    "        print \"Input the correct batch size and the total images in the dataset\"\n",
    "        exit(1)\n",
    "\n",
    "    for i in xrange(tot_images/batch_size):\n",
    "        curSet = images[i*batch_size:(i+1)*batch_size,:,:,:]\n",
    "        true_prob = np.array(lasagne.layers.get_output(net['prob'], curSet, deterministic=True).eval())\n",
    "        true_top5 = np.argsort(true_prob,axis=1)[:,-1:-6:-1]\n",
    "\n",
    "        newim = rawim[i*batch_size:(i+1)*batch_size,:,:,:].transpose(0,3,1,2)\n",
    "        final = cls.adExample(newim,np.array(gold_labels[i*batch_size:(i+1)*batch_size]),model['param values'],net['prob'],input_var)\n",
    "        final = final - mean_image[None,:,None,None]\n",
    "        adv_prob = np.array(lasagne.layers.get_output(net['prob'], final, deterministic=True).eval())\n",
    "        adv_top5 = np.argsort(adv_prob,axis=1)[:,-1:-6:-1]\n",
    "        final = final + mean_image[None,:,None,None]\n",
    "\n",
    "        for k in xrange(batch_size):\n",
    "            plt.subplot(121)\n",
    "            plt.imshow(rawim[k,:,:,:].astype('uint8'))\n",
    "            for n, label in enumerate(true_top5[k,:]):\n",
    "                plt.text(0,260,'Original Image')\n",
    "                plt.text(0, 280 + n * 20, '{}. {} {} %'.format(n+1, classes[label],true_prob[k,label]*100), fontsize=12)\n",
    "\n",
    "            plt.subplot(122)\n",
    "            plt.imshow(final[k,:,:,:].transpose(1,2,0).astype('uint8'))\n",
    "            for n, label in enumerate(adv_top5[k,:]):\n",
    "                plt.text(0,260,'Adverserial Image')\n",
    "                plt.text(240, 280 + n * 20, '{}. {} {} %'.format(n+1, classes[label],adv_prob[k,label]*100), fontsize=12)\n",
    "\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '../datasets/val_gold_labels.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-a7dfdbcf958d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mrun_fsg_adverserial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtot_images\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-a7dfdbcf958d>\u001b[0m in \u001b[0;36mrun_fsg_adverserial\u001b[1;34m(tot_images, batch_size)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrun_fsg_adverserial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtot_images\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mfind_adverserial_examples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtot_images\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-a14d0591793d>\u001b[0m in \u001b[0;36mfind_adverserial_examples\u001b[1;34m(tot_images, batch_size)\u001b[0m\n\u001b[0;32m      4\u001b[0m                    loss='softmax')\n\u001b[0;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mgold_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_gold_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mrawim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgold_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdownload_val_images\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtot_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgold_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0minput_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'inputs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-7f12e4b82fa9>\u001b[0m in \u001b[0;36mload_gold_labels\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_gold_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../datasets/val_gold_labels.txt\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: '../datasets/val_gold_labels.txt'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def run_fsg_adverserial(tot_images=1,batch_size=1):\n",
    "    find_adverserial_examples(tot_images=1,batch_size=1)\n",
    "    \n",
    "\n",
    "run_fsg_adverserial(tot_images=1,batch_size=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
