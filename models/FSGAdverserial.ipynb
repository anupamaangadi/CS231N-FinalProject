{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# EvolAdversarial 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import urllib\n",
    "import io\n",
    "import skimage.transform\n",
    "from gen_adver import FastGradient\n",
    "from textwrap import wrap\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano import pp\n",
    "import time\n",
    "\n",
    "import lasagne\n",
    "from lasagne.layers import InputLayer, DenseLayer, DropoutLayer\n",
    "from lasagne.layers.conv import Conv2DLayer as ConvLayer\n",
    "from lasagne.layers.pool import Pool2DLayer as PoolLayer\n",
    "from lasagne.layers import NonlinearityLayer\n",
    "from lasagne.layers import DropoutLayer\n",
    "from lasagne.layers import LocalResponseNormalization2DLayer as NormLayer\n",
    "from lasagne.utils import floatX\n",
    "from lasagne.nonlinearities import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_image(url,mean_image):\n",
    "    ext = url.split('.')[-1]\n",
    "    im = plt.imread(io.BytesIO(urllib.urlopen(url).read()), ext)\n",
    "    # Resize so smallest dim = 256, preserving aspect ratio\n",
    "#     print url\n",
    "    if im.ndim < 3:\n",
    "        return None, None\n",
    "    \n",
    "    h, w, _ = im.shape\n",
    "    if h < w:\n",
    "        im = skimage.transform.resize(im, (256, w*256/h), preserve_range=True)\n",
    "    else:\n",
    "        im = skimage.transform.resize(im, (h*256/w, 256), preserve_range=True)\n",
    "\n",
    "    # Central crop to 224x224\n",
    "    h, w, _ = im.shape\n",
    "    im = im[h//2-112:h//2+112, w//2-112:w//2+112]\n",
    "    rawim = np.copy(im).astype('uint8')\n",
    "    \n",
    "    # Shuffle axes to c01\n",
    "    im = np.swapaxes(np.swapaxes(im, 1, 2), 0, 1)\n",
    "    \n",
    "    # Convert to BGR\n",
    "    im = im[::-1, :, :]\n",
    "    im = im - mean_image[:,None,None]\n",
    "    return rawim, floatX(im[np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model to be trained/tested against\n",
    "\n",
    "def build_model(input_var,batch_size = None):\n",
    "    net = {}\n",
    "    net['input'] = InputLayer((batch_size, 3, 224, 224),input_var=input_var)\n",
    "    net['conv1_1'] = ConvLayer(\n",
    "        net['input'], 64, 3, pad=1)\n",
    "    net['conv1_2'] = ConvLayer(\n",
    "        net['conv1_1'], 64, 3, pad=1)\n",
    "    net['pool1'] = PoolLayer(net['conv1_2'], 2)\n",
    "    net['conv2_1'] = ConvLayer(\n",
    "        net['pool1'], 128, 3, pad=1)\n",
    "    net['conv2_2'] = ConvLayer(\n",
    "        net['conv2_1'], 128, 3, pad=1)\n",
    "    net['pool2'] = PoolLayer(net['conv2_2'], 2)\n",
    "    net['conv3_1'] = ConvLayer(\n",
    "        net['pool2'], 256, 3, pad=1)\n",
    "    net['conv3_2'] = ConvLayer(\n",
    "        net['conv3_1'], 256, 3, pad=1)\n",
    "    net['conv3_3'] = ConvLayer(\n",
    "        net['conv3_2'], 256, 3, pad=1)\n",
    "    net['conv3_4'] = ConvLayer(\n",
    "        net['conv3_3'], 256, 3, pad=1)\n",
    "    net['pool3'] = PoolLayer(net['conv3_4'], 2)\n",
    "    net['conv4_1'] = ConvLayer(\n",
    "        net['pool3'], 512, 3, pad=1)\n",
    "    net['conv4_2'] = ConvLayer(\n",
    "        net['conv4_1'], 512, 3, pad=1)\n",
    "    net['conv4_3'] = ConvLayer(\n",
    "        net['conv4_2'], 512, 3, pad=1)\n",
    "    net['conv4_4'] = ConvLayer(\n",
    "        net['conv4_3'], 512, 3, pad=1)\n",
    "    net['pool4'] = PoolLayer(net['conv4_4'], 2)\n",
    "    net['conv5_1'] = ConvLayer(\n",
    "        net['pool4'], 512, 3, pad=1)\n",
    "    net['conv5_2'] = ConvLayer(\n",
    "        net['conv5_1'], 512, 3, pad=1)\n",
    "    net['conv5_3'] = ConvLayer(\n",
    "        net['conv5_2'], 512, 3, pad=1)\n",
    "    net['conv5_4'] = ConvLayer(\n",
    "        net['conv5_3'], 512, 3, pad=1)\n",
    "    net['pool5'] = PoolLayer(net['conv5_4'], 2)\n",
    "    net['fc6'] = DenseLayer(net['pool5'], num_units=4096)\n",
    "    net['fc6_dropout'] = DropoutLayer(net['fc6'], p=0.5)\n",
    "    net['fc7'] = DenseLayer(net['fc6_dropout'], num_units=4096)\n",
    "    net['fc7_dropout'] = DropoutLayer(net['fc7'], p=0.5)\n",
    "    net['fc8'] = DenseLayer(\n",
    "        net['fc7_dropout'], num_units=1000, nonlinearity=None)\n",
    "    net['prob'] = NonlinearityLayer(net['fc8'], softmax)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load model parameters and metadata\n",
    "def load_data():\n",
    "    model = pickle.load(open('/afs/ir/users/m/e/meric/Documents/CS231N/CS231N-FinalProject/datasets/vgg19.pkl'))\n",
    "\n",
    "    classes = model['synset words']\n",
    "    mean_image= model['mean value']\n",
    "    \n",
    "    return model, classes, mean_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def download_val_images (num_ex, mean_image,gold_labels,start,end):\n",
    "    ''' \n",
    "    Dynamically downloads sample images from ImageNet.  \n",
    "    '''\n",
    "    index = urllib.urlopen('http://www.image-net.org/challenges/LSVRC/2012/ori_urls/indexval.html').read()\n",
    "    image_urls = index.split('<br>')\n",
    "    final_labels = gold_labels.copy()\n",
    "    np.random.seed(61)\n",
    "    np.random.shuffle(image_urls)\n",
    "    np.random.seed(61)\n",
    "    np.random.shuffle(final_labels)\n",
    "    result_labels = np.zeros(num_ex)\n",
    "    valid_urls = []\n",
    "    \n",
    "    allImages = []\n",
    "    path_to_im = \" /farmshare/user_data/meric\"\n",
    "\n",
    "    images = np.zeros ((num_ex, 3, 224, 224), dtype=np.float32)\n",
    "    i = 0\n",
    "    j = 0\n",
    "    used=True\n",
    "    rawim = np.zeros ((num_ex, 224, 224, 3), dtype=np.float32)\n",
    "    tot = 0\n",
    "    for im_url in image_urls[start:end+10]:\n",
    "        # only use quick downloads on flickr\n",
    "        if 'static.flickr' not in im_url:\n",
    "            continue\n",
    "            \n",
    "        rawimTemp, result = prep_image (im_url, mean_image)\n",
    "        if result is None:\n",
    "            continue\n",
    "    \n",
    "        if result.any():\n",
    "            images[i,:,:,:] = result\n",
    "            result_labels[i] = final_labels[j]\n",
    "            rawim[i,:,:,:] = rawimTemp\n",
    "            i += 1\n",
    "            tot += 1\n",
    "            valid_urls.append(im_url)\n",
    "           \n",
    "        if i >= num_ex: \n",
    "            break\n",
    "        if tot >= (end-start):\n",
    "            break\n",
    "        j += 1\n",
    "            \n",
    "    return rawim,images,result_labels,valid_urls\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_gold_labels():\n",
    "    f = open(\"../datasets/val_gold_labels.txt\",'r')\n",
    "    labels = []\n",
    "    for line in f:\n",
    "        labels.append(int(line))\n",
    "        \n",
    "    return np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def find_adverserial_examples(tot_images=1,batch_size=1,start=0,end=1, log=True):\n",
    "    \n",
    "    cls = FastGradient(num_images = batch_size,input_dim=(3,224,224), eps=0.85, \n",
    "                   loss='softmax')\n",
    "    if log:\n",
    "        print \"Finished creating Fast Gradient Sign Class......\"\n",
    "    \n",
    "    model, classes, mean_image = load_data()\n",
    "    if log:\n",
    "        print \"Finished loading data......\"\n",
    "    \n",
    "    gold_labels = load_gold_labels()\n",
    "    if log:\n",
    "        print \"Finished loading golden labels......\"\n",
    "    \n",
    "    rawim, images,gold_labels,valid_urls = download_val_images(tot_images, mean_image, gold_labels,start,end)\n",
    "    if log:\n",
    "        print \"Finished downloading images, normalizing them and extracting required number of images and labels......\"\n",
    "    \n",
    "    print len(valid_urls)\n",
    "    input_var = T.tensor4('inputs')\n",
    "    net = build_model(input_var,batch_size=batch_size)\n",
    "    lasagne.layers.set_all_param_values(net['prob'], model['param values'])\n",
    "    if log:\n",
    "        print \"Finished setting all the parameters......\"\n",
    "\n",
    "    if batch_size > tot_images:\n",
    "        print \"Input the correct batch size and/or the total images in the dataset\"\n",
    "        exit(1)\n",
    "        \n",
    "    num_iter = (end-start)/batch_size\n",
    "    trueProb_dist = []\n",
    "    advProb_dist = []\n",
    "    actualAdvProb = []\n",
    "    actualAdvLabel = []\n",
    "    actualTrueProb = []\n",
    "    actualTrueLabel = []\n",
    "    advUrl = []\n",
    "    \n",
    "    sameAdv = []\n",
    "    sameTrue = []\n",
    "\n",
    "    for i in xrange(num_iter):\n",
    "        if log:\n",
    "            print \"Started Batch Iteration \" + str(i+1) + \" out of \" + str(num_iter)\n",
    "        \n",
    "        curSet = images[i*batch_size:(i+1)*batch_size,:,:,:]\n",
    "        true_prob = np.array(lasagne.layers.get_output(net['prob'], curSet, deterministic=True).eval())\n",
    "        true_top5 = np.argsort(true_prob,axis=1)[:,-1:-6:-1]\n",
    "        trueProb_dist += list(true_prob[np.arange(batch_size),true_top5[:,0]])\n",
    "        \n",
    "        if log:\n",
    "            print \"Finished forward pass to get the True Image class probabilites......\"\n",
    "        \n",
    "        newim = rawim[i*batch_size:(i+1)*batch_size,:,:,:].transpose(0,3,1,2)\n",
    "        final = cls.adExample(newim,np.array(gold_labels[i*batch_size:(i+1)*batch_size]),model['param values'],net['prob'],input_var)\n",
    "        if log:\n",
    "            print \"Finished generation of adverserial examples for current batch......\"\n",
    "        \n",
    "        final = final - mean_image[None,:,None,None]\n",
    "        adv_prob = np.array(lasagne.layers.get_output(net['prob'], final, deterministic=True).eval())\n",
    "        adv_top5 = np.argsort(adv_prob,axis=1)[:,-1:-6:-1]\n",
    "        advProb_dist += list(adv_prob[np.arange(batch_size),adv_top5[:,0]])\n",
    "        \n",
    "        final = final + mean_image[None,:,None,None]\n",
    "        if log:\n",
    "            print \"Finished forward pass for adverserial examples\"\n",
    "\n",
    "        for k in xrange(batch_size):\n",
    "            advLabel = adv_top5[k,0]\n",
    "            trueLabel = true_top5[k,0]\n",
    "            if advLabel != trueLabel:\n",
    "                actualAdvProb.append(adv_prob[k,advLabel])\n",
    "                actualAdvLabel.append(advLabel)\n",
    "                actualTrueProb.append(true_prob[k,trueLabel])\n",
    "                actualTrueLabel.append(trueLabel)\n",
    "                advUrl.append(valid_urls[i*batch_size+k])\n",
    "            else:\n",
    "                sameAdv.append(adv_prob[k,advLabel])\n",
    "                sameTrue.append(true_prob[k,trueLabel])\n",
    "            \n",
    "            \n",
    "            plt.subplot(121)\n",
    "            plt.imshow(rawim[i*batch_size+k,:,:,:].astype('uint8'))\n",
    "            for n, label in enumerate(true_top5[k,:]):\n",
    "                plt.text(0,260,'Original Image')\n",
    "                plt.text(0, 280 + n * 20, '{}. {} {} %'.format(n+1, classes[label],true_prob[k,label]*100), fontsize=12)\n",
    "\n",
    "            plt.subplot(122)\n",
    "            plt.imshow(final[k,:,:,:].transpose(1,2,0).astype('uint8'))\n",
    "            for n, label in enumerate(adv_top5[k,:]):\n",
    "                plt.text(0,260,'Adverserial Image')\n",
    "                plt.text(340, 280 + n * 20, '{}. {} {} %'.format(n+1, classes[label],adv_prob[k,label]*100), fontsize=12)\n",
    "                    \n",
    "                \n",
    "            plt.show() \n",
    "        \n",
    "        if log:\n",
    "            print \"Finished Batch Iteration \" + str(i+1) + \" out of \" + str(num_iter)\n",
    "            \n",
    "#   Convert the lists to arrays\n",
    "    binSplit = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "    actualAdvProb = np.asarray(actualAdvProb)\n",
    "    actualAdvLabel = np.asarray(actualAdvLabel)\n",
    "    actualTrueProb = np.asarray(actualTrueProb)\n",
    "    actualTrueLabel = np.asarray(actualTrueLabel)\n",
    "    advUrl = np.asarray(advUrl)\n",
    "    \n",
    "# Open files to write the data collected into\n",
    "    text1 = open(\"highAdvProb.txt\",\"w\")\n",
    "    text2 = open(\"highAdvLabel.txt\",\"w\")\n",
    "    text3 = open(\"highTrueProb.txt\",\"w\")\n",
    "    text4 = open(\"highTrueLabel.txt\",\"w\")\n",
    "    text5 = open(\"highAdvUrl.txt\",\"w\")\n",
    "\n",
    "#   Index into the arrays to find the elements having high confidence adervarial examples\n",
    "    highAdvProb = actualAdvProb[actualAdvProb >= 0.5]\n",
    "    highAdvLabel = actualAdvLabel[actualAdvProb >= 0.5]\n",
    "    highTrueProb = actualTrueProb[actualAdvProb >= 0.5]\n",
    "    highTrueLabel = actualTrueLabel[actualAdvProb >= 0.5]\n",
    "    advUrl = advUrl[actualAdvProb >= 0.5]\n",
    "    \n",
    "#   Save the data collected to files\n",
    "    np.savetxt(text1,highAdvProb, fmt='%1.8f')\n",
    "    np.savetxt(text2,highAdvLabel, fmt='%s')\n",
    "    np.savetxt(text3,highTrueProb, fmt='%1.8f')\n",
    "    np.savetxt(text4,highTrueLabel, fmt='%s')\n",
    "    np.savetxt(text5,advUrl, fmt='%s')\n",
    "    \n",
    "    \n",
    "    highTrueProb = list(highTrueProb)\n",
    "    \n",
    "#   Plot histograms for variour purposes\n",
    "    plt.hist(trueProb_dist,bins=binSplit)\n",
    "    plt.title('Frequency Distribution of Confidences of VGG Predictions')\n",
    "    plt.xlabel('Confidences')\n",
    "    plt.ylabel('Count')\n",
    "    plt.savefig(\"true_prob_dist-2.pdf\")\n",
    "    plt.figure()\n",
    "\n",
    "    plt.hist(advProb_dist,bins=binSplit)\n",
    "    title = \"Frequency Distribution of Confidences of VGG Adverserial Example Predictions\"\n",
    "    plt.title('\\n'.join(wrap(title,60)))\n",
    "    plt.xlabel('Confidences')\n",
    "    plt.ylabel('Count')\n",
    "    plt.savefig(\"adv_prob_dist-2.pdf\")\n",
    "    plt.figure()\n",
    "\n",
    "    plt.hist(list(actualTrueProb),bins=binSplit)\n",
    "    title = \"Frequency Distribution of true class predictions having some type of adverserial image\"\n",
    "    plt.title('\\n'.join(wrap(title,60)))\n",
    "    plt.xlabel('Confidences of true predictions')\n",
    "    plt.ylabel('Counts')\n",
    "    plt.savefig(\"true_having_some_adv-2.pdf\")\n",
    "    plt.figure()\n",
    "    \n",
    "    plt.hist(highTrueProb,bins=binSplit)\n",
    "    title = \"Frequency Distribution of true class predictions having an adverserial image with >50% confidence\"\n",
    "    plt.title('\\n'.join(wrap(title,60)))\n",
    "    plt.xlabel('Confidences of true predictions')\n",
    "    plt.ylabel('Counts')\n",
    "    plt.savefig(\"true_having_high_adv-2.pdf\")\n",
    "    plt.figure()\n",
    "    \n",
    "    plt.hist(sameTrue,bins=binSplit)\n",
    "    title = \"Frequency Distribution of true class predictions not perturbed in their adverserial examples\"\n",
    "    plt.title('\\n'.join(wrap(title,60)))\n",
    "    plt.xlabel('Confidences of true predictions')\n",
    "    plt.ylabel('Counts')\n",
    "    plt.savefig(\"true_having_same_adv-2.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating Fast Gradient Sign Class......\n",
      "Finished loading data......\n",
      "Finished loading golden labels......\n",
      "Finished downloading images, normalizing them and extracting required number of images and labels......\n",
      "2\n",
      "Finished setting all the parameters......\n",
      "Started Batch Iteration 1 out of 1\n",
      "Finished forward pass to get the True Image class probabilites......\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def run_fsg_adverserial(tot_images=1,batch_size=1,start=0,end=1):\n",
    "    find_adverserial_examples(tot_images=tot_images,batch_size=batch_size,start=start,\n",
    "                              end=end,log=True)\n",
    "    \n",
    "\n",
    "t1 = time.time()\n",
    "run_fsg_adverserial(tot_images=2,batch_size=2, start=0,end=2)\n",
    "t2 = time.time()\n",
    "print \"Time taken to execute program is \" + str(t2-t1) + \" seconds\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
