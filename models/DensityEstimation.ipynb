{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Does density estimation\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib as plt\n",
    "import cPickle as pickle\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano import pp\n",
    "\n",
    "import lasagne\n",
    "from time import time\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.zeros((100, 2))\n",
    "data[:20] = 3 * np.random.randn(20, 2) + np.array([10, 10])\n",
    "\n",
    "data[20:40] = 3 * np.random.randn(20, 2) + np.array([-10, -10])\n",
    "              \n",
    "data[40:60] = 10 * np.random.randn(20, 2) + np.array([20, -20])\n",
    "    \n",
    "data[60:] = (2 ** np.random.uniform(-3, 5, (40, 2))) + np.array([-10, 15]) \n",
    "data = data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kernel = stats.gaussian_kde(data, 'silverman')\n",
    "xmin, ymin = tuple(np.min(data, axis=1)[:2])\n",
    "xmax, ymax = tuple(np.max(data, axis=1)[:2])\n",
    "\n",
    "print xmin, ymin\n",
    "\n",
    "print xmax, ymax\n",
    "\n",
    "x_vals = data[0, :]\n",
    "y_vals = data[1, :]\n",
    "\n",
    "print x_vals.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_density (kernel):\n",
    "    \n",
    "    X, Y = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
    "    positions = np.vstack([X.ravel(), Y.ravel()])\n",
    "    values = kernel(positions).T\n",
    "    Z = np.reshape(values, X.shape)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(np.rot90(Z), cmap=plt.cm.gist_earth_r,\n",
    "              extent=[xmin, xmax, ymin, ymax])\n",
    "    ax.plot(x_vals, y_vals, 'k.', markersize=2)\n",
    "    ax.set_xlim([xmin, xmax])\n",
    "    ax.set_ylim([ymin, ymax])\n",
    "    plt.title('Kernel Density Estimation')\n",
    "    plt.savefig('kde.png', dpi=500)\n",
    "    #plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'xmin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-26c316cfdf6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_density\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-20add2659d3c>\u001b[0m in \u001b[0;36mplot_density\u001b[0;34m(kernel)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_density\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgrid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mxmax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100j\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mymin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mymax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100j\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mpositions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'xmin' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plot_density(kernel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now let's try to load PCA features and run the autoencoder on them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.decomposition.pca.PCA'>\n",
      "(128, 4096)\n",
      "(828, 128)\n"
     ]
    }
   ],
   "source": [
    "import autoencoder\n",
    "import multiprocessing as mp\n",
    "\n",
    "_prefix = '../../../231n_results/'\n",
    "\n",
    "def load_pca_feat (syn='n02119789'):\n",
    "    with open(_prefix + 'train_features/{0}_pca_128'.format(syn), 'rb') as f:\n",
    "        pca_feat = pickle.load(f)\n",
    "        \n",
    "    return pca_feat\n",
    "\n",
    "def load_pca_model (syn = 'n02119789'):\n",
    "    \n",
    "    \n",
    "    with open(_prefix + 'train_pca/{0}_pca_model'.format(syn), 'rb') as f:\n",
    "        pca_model = pickle.load(f)\n",
    "        \n",
    "    return pca_model\n",
    "\n",
    "def parallelize_batch (fn, args, batch_size):\n",
    "    \"\"\" \n",
    "    Parallelizes the function into the given batches.\n",
    "    \"\"\"\n",
    "    pool = mp.Pool(8)\n",
    "    \n",
    "    for i in np.arange(0, len(args), batch_size):        \n",
    "        yield pool.map(fn, args[i:i+batch_size])\n",
    "\n",
    "\n",
    "arr = load_pca_feat()\n",
    "\n",
    "model = load_pca_model()\n",
    "print type(model)\n",
    "print model.components_.shape\n",
    "print arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "---\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "---\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "---\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "---\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "---\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "---\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "---\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "---\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "---\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "---\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "---\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "---\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "(1500, 128)\n",
      "---\n",
      "47.7015039921  seconds elapsed\n"
     ]
    }
   ],
   "source": [
    "fake = np.random.random((1500, 4096))\n",
    "args = !head -n 100 ../util/synsets\n",
    "\n",
    "\n",
    "t0 = time()\n",
    "for features in parallelize_batch (load_pca_model, args, 8):\n",
    "    for m in features:\n",
    "\n",
    "        print m.transform(fake).shape \n",
    "    print '---'\n",
    "t1 = time()\n",
    "\n",
    "print t1 - t0, \" seconds elapsed\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "fake_data = np.random.random((3000,4096))\n",
    "# try it in sklearn\n",
    "A = model.transform(fake_data)\n",
    "# Implement the data-centered projection yourself\n",
    "B = np.dot(fake_data - model.mean_, model.components_.T)\n",
    "\n",
    "print np.allclose(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_encoder():\n",
    "    net, input_var, target_var, init_weights = autoencoder.buildEncoder()\n",
    "    half_network = lasagne.layers.get_output (net['h3'], input_var, deterministic=True)\n",
    "    predict_fn = theano.function([input_var], half_network)\n",
    "    \n",
    "    return net, predict_fn\n",
    "\n",
    "# Load the autoencoder weights from file \n",
    "def load_weights_for(syn):\n",
    "    \n",
    "    ''' Loads weights for a synset into the autoencoder '''\n",
    "    \n",
    "    with open(_prefix + 'train_autoencode/{0}.pkl'.format('n02119789'), 'rb') as f:\n",
    "        weights = pickle.load(f)\n",
    "    return weights\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get prediction\n",
    "\n",
    "def load_weights_and_pca_feat (syn):\n",
    "    weights = load_weights_for (syn)\n",
    "    feat = load_pca_feat (syn)\n",
    "    return feat, weights\n",
    "\n",
    "def form_density_priors (vgg_out=None):\n",
    "    '''\n",
    "    Forms the priors as described in the paper.\n",
    "    Input:\n",
    "    - vgg_out: the forward pass of vgg up to 4096.  \n",
    "    '''\n",
    "    \n",
    "    O, C = 128, 10\n",
    "    \n",
    "    encoder,predict_fn = prep_encoder()\n",
    "    if vgg_out is None:\n",
    "        # random input\n",
    "        N, I = 1500, 4096\n",
    "        vgg_out = np.random.random((N, I))\n",
    "    else:\n",
    "        N, I = vgg_out.shape\n",
    "\n",
    "\n",
    "\n",
    "    # Get output of lasagne function forward pass ...\n",
    "\n",
    "    projected = np.zeros ((C, N, O))\n",
    "    args = !head -n 10 ../util/synsets\n",
    "\n",
    "    t0 = time()\n",
    "    i = 0\n",
    "    for features in parallelize_batch (load_pca_model, args, 8):\n",
    "        for m in features:\n",
    "            projected[i, :, :] = m.transform(vgg_out)\n",
    "            i += 1\n",
    "        print i, '---'\n",
    "\n",
    "    t1 = time()\n",
    "\n",
    "    print t1 - t0, \" seconds elapsed for pca compression\"\n",
    "\n",
    "    # enc_out = np.zeros ((C, N, 8))\n",
    "    # Run the autoencoder forward pass, making sure to calculate the pca features too...\n",
    "    j = 0\n",
    "    density = np.zeros ((C, N))\n",
    "\n",
    "    for entry in parallelize_batch (load_weights_and_pca_feat, args, 8):\n",
    "\n",
    "        for feat, w in entry:\n",
    "            lasagne.layers.set_all_param_values (encoder['h0_inv'], w)\n",
    "            class_out = predict_fn (feat)\n",
    "            print \"shape: \", feat.shape\n",
    "            enc_out[j, :, :] = predict_fn (projected[j, :, :])\n",
    "            \n",
    "            # form density estimate\n",
    "            kernel = stats.gaussian_kde(class_out.T, 'silverman')\n",
    "            # scale density by number of support examples\n",
    "            density[j, :] =  kernel(enc_out[j, :, :].T) * (1.0 * feat.shape[0])\n",
    "\n",
    "            j += 1\n",
    "        print '---'\n",
    "\n",
    "    print density.shape\n",
    "\n",
    "    t2 = time()\n",
    "\n",
    "    print \"Total time elapsed: {0:.3f}\".format(t2 - t0)\n",
    "    print density[1]    \n",
    "    return density\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['h0', 'h1', 'h2', 'h3'] ['h3_inv', 'h2_inv', 'h1_inv', 'h0_inv']\n",
      "h3\n",
      "h2\n",
      "h1\n",
      "h0\n",
      "8 ---\n",
      "10 ---\n",
      "5.73501706123  seconds elapsed for pca compression\n",
      "shape:  (828, 128)\n",
      "shape:  (2425, 128)\n",
      "shape:  (1295, 128)\n",
      "shape:  (1078, 128)\n",
      "shape:  (1457, 128)\n",
      "shape:  (1355, 128)\n",
      "shape:  (1685, 128)\n",
      "shape:  (976, 128)\n",
      "---\n",
      "shape:  (1499, 128)\n",
      "shape:  (1661, 128)\n",
      "---\n",
      "(10, 1500)\n",
      "Total time elapsed: 10.479\n",
      "[  1.25349577e-11   1.24386824e-11   1.22403440e-11 ...,   1.30506154e-11\n",
      "   1.25607726e-11   1.29403459e-11]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  8.19398437e-13,   8.34086487e-13,   7.85250497e-13, ...,\n",
       "          7.75974154e-13,   7.73758011e-13,   7.71241089e-13],\n",
       "       [  1.25349577e-11,   1.24386824e-11,   1.22403440e-11, ...,\n",
       "          1.30506154e-11,   1.25607726e-11,   1.29403459e-11],\n",
       "       [  5.62000796e-12,   5.50479164e-12,   5.85104494e-12, ...,\n",
       "          5.81987210e-12,   5.70965233e-12,   6.13103306e-12],\n",
       "       ..., \n",
       "       [  8.57108833e-13,   8.05859242e-13,   7.61615638e-13, ...,\n",
       "          7.40554681e-13,   8.07689956e-13,   7.67844420e-13],\n",
       "       [  4.55861299e-13,   2.97464331e-13,   4.04585581e-13, ...,\n",
       "          4.25427124e-13,   3.90100288e-13,   4.40677972e-13],\n",
       "       [  3.06753517e-12,   3.11616273e-12,   3.05978834e-12, ...,\n",
       "          2.97308143e-12,   3.15262148e-12,   3.12172397e-12]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "form_density_priors()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 0.00197 seconds\n",
      "(828, 8)\n",
      "[[ -9.46687926   7.97486458   3.08886186 ...,  -3.98335123  -3.78375334\n",
      "  -11.0877427 ]\n",
      " [-25.66383404  44.98688498  76.15668582 ...,  13.15595439  33.90102597\n",
      "   -5.65971174]\n",
      " [-14.99782005  -5.20245933 -10.54871752 ...,  -6.23067025  34.19341269\n",
      "   -2.845946  ]\n",
      " ..., \n",
      " [-13.8221054   33.908136    24.41835241 ...,  -7.14355531  14.4476518\n",
      "    9.46470871]\n",
      " [-15.16963036  -9.10386447  16.65445596 ...,   1.1607423   14.21803342\n",
      "  -15.26398011]\n",
      " [-27.29592561  13.59560444  -1.61078381 ..., -12.30310593   8.94842863\n",
      "   -6.66754043]]\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "res = predict_fn(arr)\n",
    "t1 = time()\n",
    "print \"took {0:.5f} seconds\".format(t1 - t0)\n",
    "print res.shape\n",
    "print res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000581979751587\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "kernel = stats.gaussian_kde(res.T, 'silverman')\n",
    "t1 = time()\n",
    "print t1 - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(828, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.4459298097040501e-13"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print res.shape\n",
    "np.max(kernel(res.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.52385161455e-14\n",
      "Mean probability of other class:  7.97435406954e-14\n"
     ]
    }
   ],
   "source": [
    "# Test linear interpolation\n",
    "\n",
    "\n",
    "print np.min(kernel(res.T))\n",
    "\n",
    "\n",
    "# load other data\n",
    "\n",
    "other_data = load_pca_feat (syn='n02509815')\n",
    "other_small = predict_fn(other_data)\n",
    "\n",
    "print \"Mean probability of other class: \", np.mean(kernel(other_small.T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
